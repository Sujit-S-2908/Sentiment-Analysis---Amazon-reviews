{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d tarkkaanko/amazon\n",
        "!unzip amazon.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQG2ccYWUPMO",
        "outputId": "6a1a903f-9bcb-4a7f-9c5a-2121378623d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/tarkkaanko/amazon\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "amazon.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  amazon.zip\n",
            "replace amazon_reviews.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "y7Kr3k_rUThi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Amazon reviews dataset\n",
        "df = pd.read_csv('amazon_reviews.csv')\n",
        "\n",
        "# Print the column names to verify\n",
        "print(df.columns)\n",
        "\n",
        "# Drop missing values - adjust column names if necessary based on the output above\n",
        "df.dropna(subset=['reviewText', 'overall'], inplace=True) # Example: Assuming 'reviewID' and 'overall' are the actual column names\n",
        "\n",
        "# Convert ratings to sentiment labels (negative: 0, neutral: 1, positive: 2)\n",
        "def map_sentiment(rating):\n",
        "    if rating == 3:\n",
        "        return 1  # Neutral\n",
        "    elif rating > 3:\n",
        "        return 2  # Positive\n",
        "    else:\n",
        "        return 0  # Negative\n",
        "\n",
        "df['sentiment'] = df['overall'].apply(map_sentiment) # Example: Using 'overall' to calculate sentiment\n",
        "\n",
        "# Keep only relevant columns\n",
        "df = df[['reviewText', 'sentiment']] # Example: Assuming 'reviewText' is the relevant column for reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B14fRDZYWD3y",
        "outputId": "30194857-fd3b-4953-dd36-8a8631eabd97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'reviewerName', 'overall', 'reviewText', 'reviewTime',\n",
            "       'day_diff', 'helpful_yes', 'helpful_no', 'total_vote',\n",
            "       'score_pos_neg_diff', 'score_average_rating', 'wilson_lower_bound'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing and padding text data\n",
        "max_words = 20000\n",
        "max_len = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df['reviewText'])\n",
        "\n",
        "# Convert reviews to sequences\n",
        "sequences = tokenizer.texts_to_sequences(df['reviewText'])\n",
        "\n",
        "# Pad sequences\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Prepare labels\n",
        "labels = df['sentiment'].values"
      ],
      "metadata": {
        "id": "YXHXF89uWOc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zj8aS5i4WVby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the RNN model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "model.add(tf.keras.layers.Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
        "\n",
        "# Simple RNN layer\n",
        "model.add(tf.keras.layers.SimpleRNN(64))\n",
        "\n",
        "# Output layer with 3 classes (negative, neutral, positive)\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "2wsbJEcPWXDo",
        "outputId": "15b8dbd8-044d-48e2-8be9-0fe20095fb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              â”‚ ?                           â”‚     \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ simple_rnn_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)             â”‚ ?                           â”‚     \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ ?                           â”‚     \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              â”‚ ?                           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ simple_rnn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             â”‚ ?                           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ ?                           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_Wx8jlWWZDe",
        "outputId": "0a7ea3f9-2d70-47b7-a733-827d74bc30ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.8514 - loss: 0.5183 - val_accuracy: 0.9125 - val_loss: 0.3498\n",
            "Epoch 2/5\n",
            "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.9043 - loss: 0.3433 - val_accuracy: 0.9095 - val_loss: 0.3133\n",
            "Epoch 3/5\n",
            "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.9507 - loss: 0.1690 - val_accuracy: 0.9176 - val_loss: 0.2933\n",
            "Epoch 4/5\n",
            "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 66ms/step - accuracy: 0.9886 - loss: 0.0567 - val_accuracy: 0.9176 - val_loss: 0.3141\n",
            "Epoch 5/5\n",
            "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.9980 - loss: 0.0157 - val_accuracy: 0.9166 - val_loss: 0.3552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufCVmF0NWc2A",
        "outputId": "8bafb1ba-045b-4842-81b7-1e1d395f93e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9176 - loss: 0.3105\n",
            "Test accuracy: 0.9165818691253662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def predict_sentiment(review):\n",
        "#     # Convert the review to a sequence\n",
        "#     sequence = tokenizer.texts_to_sequences([review])\n",
        "#     padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
        "\n",
        "#     # Predict the sentiment\n",
        "#     prediction = model.predict(padded_sequence)\n",
        "\n",
        "#     # Return the sentiment class with the highest probability\n",
        "#     sentiment = np.argmax(prediction)\n",
        "\n",
        "#     return ['Negative', 'Neutral', 'Positive'][sentiment]\n",
        "\n",
        "# # Example usage\n",
        "# review_text = \"The phone is amazing, love the battery life!\"\n",
        "# print(predict_sentiment(review_text))  # Output: Positive"
      ],
      "metadata": {
        "id": "5br0udjCWhYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Function to extract reviews from an Amazon product page and store them in a dataframe\n",
        "def scrape_amazon_reviews(url):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    # Send a request to the URL\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Parse the page content\n",
        "    soup = BeautifulSoup(response.content, 'lxml')\n",
        "\n",
        "    # Find all reviews\n",
        "    # If the reviews are under a different tag or class, update the query\n",
        "    reviews = soup.find_all('div', {'class': 'a-row a-spacing-small review-data'})\n",
        "\n",
        "\n",
        "    print(f\"Found {len(reviews)} reviews\")\n",
        "\n",
        "    review_texts = []\n",
        "    for review in reviews:\n",
        "        review_text = review.get_text().strip()\n",
        "        review_texts.append(review_text)\n",
        "\n",
        "    # Create a dataframe with the reviews regardless of whether reviews were found or not\n",
        "    reviews_df = pd.DataFrame(review_texts, columns=['ReviewText'])\n",
        "\n",
        "    if not review_texts:\n",
        "        print(\"No reviews found. The page structure might have changed.\")\n",
        "\n",
        "    return reviews_df\n",
        "\n",
        "# Example usage with an Amazon product URL (replace with actual URL)\n",
        "url = 'https://www.amazon.in/Airdopes-141-Playtime-Resistance-Bluetooth/dp/B09N3ZNHTY/ref=s9_acsd_al_ot_c2_x_2_t?_encoding=UTF8&pf_rd_m=A21TJRUUN4KGV&pf_rd_s=merchandised-search-8&pf_rd_r=N3CV8A3HBP0C3G2MBVZ5&pf_rd_p=c1af48d3-bf91-454b-b64e-bfa6ef7d10a0&pf_rd_t=&pf_rd_i=1388921031'  # Example URL, replace with the correct one\n",
        "reviews_df = scrape_amazon_reviews(url)\n",
        "\n",
        "# Display the dataframe\n",
        "print(reviews_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmD2jEGDYOY_",
        "outputId": "e1c681cc-d9a5-4c10-a938-efeabdd47010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13 reviews\n",
            "                                           ReviewText\n",
            "0   Pros>Only sound quality is good.Durable. They'...\n",
            "1   Pros:1. The level of volume it gets to, is jus...\n",
            "2   I am writing a true review after around a week...\n",
            "3   I'm writing this review after 2 years of buyin...\n",
            "4   Sound quality is good. But within 12 months th...\n",
            "5   It is a very good product and all the features...\n",
            "6   Great for listening to music or watching a mov...\n",
            "7   After 1 year one was not working properly\\nRea...\n",
            "8   I have been using boAt headphones for a year n...\n",
            "9                             Good Quality\\nRead more\n",
            "10  its a amazing product, worth for money, awesom...\n",
            "11              Good item, I like it ğŸ”¥boat\\nRead more\n",
            "12                              i like it!\\nRead more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming model, tokenizer, and max_len are defined and loaded\n",
        "\n",
        "# Function to predict sentiment of multiple reviews and store them in the dataframe\n",
        "def predict_sentiment_for_reviews(reviews_df, model, tokenizer, max_len):\n",
        "    predictions = []\n",
        "\n",
        "    for review in reviews_df['ReviewText']:\n",
        "        sequence = tokenizer.texts_to_sequences([review])\n",
        "        padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
        "        prediction = model.predict(padded_sequence)\n",
        "        sentiment = np.argmax(prediction)\n",
        "        sentiment_label = ['Negative', 'Neutral', 'Positive'][sentiment]\n",
        "        predictions.append(sentiment_label)\n",
        "\n",
        "    # Add the sentiment predictions to the dataframe\n",
        "    reviews_df['PredictedSentiment'] = predictions\n",
        "    return reviews_df\n",
        "\n",
        "# Predict sentiment for the scraped reviews\n",
        "reviews_with_sentiment = predict_sentiment_for_reviews(reviews_df, model, tokenizer, max_len=100)\n",
        "\n",
        "# Display the dataframe with reviews and predicted sentiment\n",
        "print(reviews_with_sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUvGA30WYxts",
        "outputId": "d820bfa1-173d-47e8-ae0a-eb01a38d62ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "                                           ReviewText PredictedSentiment\n",
            "0   Pros>Only sound quality is good.Durable. They'...           Positive\n",
            "1   Pros:1. The level of volume it gets to, is jus...           Positive\n",
            "2   I am writing a true review after around a week...           Positive\n",
            "3   I'm writing this review after 2 years of buyin...           Positive\n",
            "4   Sound quality is good. But within 12 months th...           Positive\n",
            "5   It is a very good product and all the features...           Positive\n",
            "6   Great for listening to music or watching a mov...           Positive\n",
            "7   After 1 year one was not working properly\\nRea...           Positive\n",
            "8   I have been using boAt headphones for a year n...           Positive\n",
            "9                             Good Quality\\nRead more           Positive\n",
            "10  its a amazing product, worth for money, awesom...           Positive\n",
            "11              Good item, I like it ğŸ”¥boat\\nRead more           Positive\n",
            "12                              i like it!\\nRead more           Positive\n"
          ]
        }
      ]
    }
  ]
}